{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autonomous driving - Car detection\n",
    "\n",
    "Aprenderá sobre la detección de objetos utilizando el modelo YOLO. Muchas de las ideas de este cuaderno se describen en los dos papers de YOLO: [Redmon et al., 2016](https://arxiv.org/abs/1506.02640) y [Redmon and Farhadi, 2016](https://arxiv.org/abs/1612.08242). Descargar previamente la carpeta [yad2k](https://github.com/allanzelener/YAD2K) a su escritorio y la carpeta [model_data](https://drive.google.com/file/d/1W3rqk19V_iI5_0vbwhIx2y1QwRZonLcC/view?usp=sharing) que contiene los pesos, clases y anchor boxes de YoloV2\n",
    "\n",
    "**Aprenderás a**:\n",
    "- Usar la detección de objetos en un conjunto de datos de detección de automóviles\n",
    "- Tratar con cajas delimitadoras(bounding boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from yad2k.models.keras_yolo import yolo_head\n",
    "from yad2k.utils.yolo_utils import draw_boxes, get_colors_for_classes, scale_boxes, read_classes, read_anchors, preprocess_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Planteamiento del problema\n",
    "\n",
    "Estás trabajando en un coche autónomo. Como componente crítico de este proyecto, primero le gustaría construir un sistema de detección de automóviles. Para recopilar datos, instaló una cámara en el capó (es decir, en la parte delantera) del automóvil, que toma imágenes de la carretera cada pocos segundos mientras conduce\n",
    "\n",
    "<center>\n",
    "<video width=\"400\" height=\"200\" src=\"image/nb_images/road_video_compressed2.mp4\" type=\"video/mp4\" controls>\n",
    "</video>\n",
    "</center>\n",
    "\n",
    "<caption><center> Fotos tomadas de una cámara montada en automóvil mientras conducen alrededor de Silicon Valley. <br> Dataset provided by <a href=\"https://www.drive.ai/\">drive.ai</a>.\n",
    "</center></caption>\n",
    "\n",
    "Reunió todas estas imágenes en una carpeta y las etiquetó dibujando cuadros delimitadores alrededor de cada automóvil que encontró. Aquí hay un ejemplo de cómo se ven sus cuadros delimitadores.\n",
    "\n",
    "<img src=\"image/nb_images/box_label.png\" style=\"width:500px;height:250;\">\n",
    "<caption><center> <u><b>Figure 1</u></b>: Definició de un box<br> </center></caption>\n",
    "\n",
    "Si tiene 80 clases que desea que reconozca el detector de objetos, puede representar la etiqueta de clase $c$ ya sea como un número entero del 1 al 80, o como un vector de 80 dimensiones (con 80 números), uno de cuyos componentes es 1 y el resto de los cuales son 0. \n",
    "\n",
    "En este ejercicio, aprenderá cómo \"You Only Look Once\" (YOLO) **realiza la detección de objetos y luego lo aplicará a la detección de automóviles**. Debido a que el modelo YOLO es computacionalmente muy costoso de entrenar, cargaremos pesos previamente entrenados para que los use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. YOLO\n",
    "\n",
    "\"You Only Look Once\" (YOLO) es un algoritmo popular porque logra un alto accuracy y al mismo tiempo puede ejecutarse en tiempo real. Este algoritmo \"Solo se ve una vez\" la imagen en el sentido de que requiere solo un paso de propagación hacia adelante a través de la red para hacer predicciones. Después de la `supresión no máxima`, luego genera objetos reconocidos junto con los cuadros delimitadores.\n",
    "\n",
    "### 2.1 - Detalles del modelo\n",
    "\n",
    "#### Inputs y outputs\n",
    "- El **input** es un batch de imagenes, y cada imagen tiene la forma (m, 608, 608, 3)\n",
    "- El **output** es una lista de cuadros delimitadores junto con las clases reconocidas. Cada cuadro delimitador está representado por 6 números $(p_c, b_x, b_y, b_h, b_w, c)$ como se explicó anteriormente. `Si expandes $c$ en un vector de 80 dimensiones, cada cuadro delimitador se representa mediante 85 números.`\n",
    "\n",
    "#### Anchor Boxes\n",
    "* Los Anchor boxes se eligen **mediante la exploración de los datos de entrenamiento** para elegir proporciones razonables de height/width que representen las diferentes clases. Para esta tarea, **se eligieron 5 cuadros de anclaje** (para cubrir las 80 clases) y se almacenaron en el archivo './model_data/yolo_anchors.txt'\n",
    "* La dimensión para los Anchor boxes es la penúltima dimensión en la codificación: $(m, n_H,n_W,anchors,classes)$.\n",
    "* La arquitectura de YOLO es: `IMAGE (m, 608, 608, 3) -> DEEP CNN -> ENCODING (m, 19, 19, 5, 85)`.   \n",
    "\n",
    "#### Encoding\n",
    "Veamos con mayor detalle lo que representa esta codificación.\n",
    "\n",
    "<img src=\"image/nb_images/architecture.png\" style=\"width:700px;height:400;\">\n",
    "<caption><center> <u><b> Figure 2 </u></b>: Arquitectura de codificación para yolo<br> </center></caption>\n",
    "\n",
    "Si el centro/punto medio de un objeto cae en una celda de cuadrícula, esa celda de cuadrícula es responsable de detectar ese objeto.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que estamos usando 5 *cuadros de anclaje*, cada una de las **celdas de 19 x 19** codifica información sobre 5 cuadros. **Los cuadros de anclaje se definen solo por su ancho y alto**.\n",
    "\n",
    "Para simplificar, aplanaremos las dos últimas dimensiones de la codificación de la forma (19, 19, 5, 85). Entonces la salida del Deep CNN es (19, 19, 425).\n",
    "\n",
    "<img src=\"image/nb_images/flatten.png\" style=\"width:700px;height:400;\">\n",
    "<caption><center> <u><b> Figure 3 </u></b>: Aplanando las últimas dos dimensiones<br> </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class score\n",
    "\n",
    "Ahora, para cada box (de cada celda) calcularemos el siguiente producto por elementos y extraeremos una probabilidad de que la Caja contenga una cierta clase.\n",
    "El score de la clase es $score_{c,i} = p_{c} \\times c_{i}$, $p_{c}$ : la probabilidad de que haya un objeto, $c_{i}$ : la probabilidad de que el objeto sea de cierta clase $c_{i}$.\n",
    "\n",
    "<img src=\"image/nb_images/probability_extraction.png\" style=\"width:700px;height:400;\">\n",
    "<caption><center> <u><b>Figure 4 </b></u>: Encuentre la clase detectada por cada caja<br> </center></caption>\n",
    "\n",
    "##### Ejemplo de la figura 4\n",
    "* En la figura 4, digamos para el cuadro 1 (celda 1), la probabilidad de que exista un objeto es $p_{1}=0.60$. Entonces, hay un 60% de posibilidades de que exista un objeto en el cuadro 1 (celda 1).\n",
    "* La probabilidad de que el objeto sea de la clase \"categoría 3 (un coche)\" es $c_{3}=0,73$.\n",
    "* La puntuación de la casilla 1 y de la categoría \"3\" es $score_{1,3}=0,60 \\times 0,73 = 0,44$.\n",
    "* Digamos que calculamos el puntaje para las 80 clases en el cuadro 1 y encontramos que el puntaje para la clase de automóvil (clase 3) es el máximo. Así que asignaremos el puntaje 0.44 y la clase \"3\" a este cuadro \"1\".\n",
    "\n",
    "#### Visualizando clases\n",
    "Aquí hay una forma de visualizar lo que YOLO está prediciendo en una imagen:\n",
    "- Para cada una de las celdas de la cuadrícula de 19x19, encuentre el máximo de los scores de probabilidad (tomando un máximo entre las 80 clases, un máximo para cada uno de los 5 cuadros de anclaje).\n",
    "- Colorea esa celda de cuadrícula de acuerdo con el objeto que esa celda de cuadrícula considere más probable.\n",
    "\n",
    "Hacer esto da como resultado esta imagen:\n",
    "\n",
    "<img src=\"image/nb_images/proba_map.png\" style=\"width:300px;height:300;\">\n",
    "<caption><center> <u><b>Figure 5 </b></u>: Cada una de las celdas de la cuadrícula de 19x19 está coloreada de acuerdo con la clase que tiene la mayor probabilidad prevista en esa celda. <br> </center></caption>\n",
    "\n",
    "Tenga en cuenta que esta visualización no es una parte central del algoritmo YOLO en sí mismo para hacer predicciones; *es solo una buena forma de visualizar un resultado intermedio del algoritmo.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing bounding boxes\n",
    "Otra forma de visualizar la salida de YOLO es trazar los cuadros delimitadores que genera. Hacer eso da como resultado una visualización como esta:\n",
    "\n",
    "<img src=\"image/nb_images/anchor_map.png\" style=\"width:200px;height:200;\">\n",
    "<caption><center> <u> Figure 6 </u>: Cada celda te da 5 cajas. En total, el modelo predice: 19x19x5 = 1805 cajas con solo mirar una vez la imagen (¡un paso hacia adelante a través de la red)! Diferentes colores denotan diferentes clases. <br> </center></caption>\n",
    "\n",
    "#### Non-Max suppression\n",
    "En la figura anterior, trazamos solo casillas para las que el modelo había asignado una probabilidad alta, pero todavía son demasiadas casillas. Le gustaría reducir la salida del algoritmo a un número mucho menor de objetos detectados.\n",
    "\n",
    "Para ello, utilizará **non-max suppression**. En concreto, llevarás a cabo estos pasos:\n",
    "- **Deshágase de las casillas con un score bajo** (lo que significa que la casilla no tiene mucha confianza para detectar una clase, ya sea debido a la baja probabilidad de cualquier objeto o a la baja probabilidad de esta clase en particular).\n",
    "- Seleccionar solo una casilla cuando varias casillas se superponen entre sí y detectan el mismo objeto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Filtrando con un umbral en las class scores\n",
    "Primero va a aplicar un filtro por umbral. Le gustaría deshacerse de cualquier casilla para la cual el \"score\" de la clase sea inferior al umbral elegido.\n",
    "\n",
    "El modelo te da un total de 19x19x5x85 números, con cada casilla descrita por 85 números. Es conveniente reordenar el tensor dimensional (19,19,5,85) (o (19,19,425)) en las siguientes variables:\n",
    "- `box_confidence`: tensor de forma $(19, 19, 5, 1)$ que contiene $p_c$ (probabilidad de confianza de que haya algún objeto) para cada una de las 5 casillas previstas en cada una de las celdas de 19x19.\n",
    "- `boxes`: tensor de forma $(19, 19, 5, 4)$ que contiene el punto medio y las dimensiones $(b_x, b_y, b_h, b_w)$ para cada una de las 5 casillas de cada celda.\n",
    "- `box_class_probs`: tensor de forma $(19, 19, 5, 80)$ que contiene las \"probabilidades de clase\" $(c_1, c_2, ... c_{80})$ para cada una de las 80 clases para cada una de las 5 casillas por celda.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_filter_boxes(boxes, box_confidence, box_class_probs, threshold = 0.6):\n",
    "    \"\"\"Filtra los cuadros de YOLO al establecer un umbral de confianza de clase y objeto.    \n",
    "    Arguments:\n",
    "        boxes -- tensor of shape (19, 19, 5, 4)\n",
    "        box_confidence -- tensor of shape (19, 19, 5, 1)\n",
    "        box_class_probs -- tensor of shape (19, 19, 5, 80)\n",
    "        threshold -- valor real, if [puntuación de probabilidad de clase más alta < umbral], deshágase de la casilla correspondiente \"\"\"\n",
    "\n",
    "    box_scores = box_class_probs*box_confidence  # (19,19,5,80)\n",
    "\n",
    "    # Encuentre box_classes usando max box_scores, realice un seguimiento de la score correspondiente\n",
    "    box_classes = tf.argmax(box_scores, axis = -1) # (19,19,5)\n",
    "    box_class_scores = tf.reduce_max(box_scores, axis = -1) # (19,19,5)\n",
    "\n",
    "    # Cree una máscara de filtrado basada en \"box_class_scores\" usando \"umbral\"\n",
    "    # casillas que desea conservar (con probabilidad >= umbral)\n",
    "    filtering_mask = (box_class_scores >= threshold) \n",
    "\n",
    "    # Aplicar la máscara a box_class_scores, boxes y box_classes\n",
    "    scores = tf.boolean_mask(box_class_scores, filtering_mask)\n",
    "    boxes = tf.boolean_mask(boxes, filtering_mask)\n",
    "    classes = tf.boolean_mask(box_classes, filtering_mask)\n",
    "\n",
    "    return scores, boxes, classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores[2] = 9.270486\n",
      "boxes[2] = [ 4.6399336  3.2303846  4.431282  -2.202031 ]\n",
      "classes[2] = 8\n",
      "scores.shape = (1789,)\n",
      "boxes.shape = (1789, 4)\n",
      "classes.shape = (1789,)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(10)\n",
    "box_confidence = tf.random.normal([19, 19, 5, 1], mean=1, stddev=4, seed = 1)\n",
    "boxes = tf.random.normal([19, 19, 5, 4], mean=1, stddev=4, seed = 1)\n",
    "box_class_probs = tf.random.normal([19, 19, 5, 80], mean=1, stddev=4, seed = 1)\n",
    "scores, boxes, classes = yolo_filter_boxes(boxes, box_confidence, box_class_probs, threshold = 0.5)\n",
    "print(\"scores[2] = \" + str(scores[2].numpy()))\n",
    "print(\"boxes[2] = \" + str(boxes[2].numpy()))\n",
    "print(\"classes[2] = \" + str(classes[2].numpy()))\n",
    "print(\"scores.shape = \" + str(scores.shape))\n",
    "print(\"boxes.shape = \" + str(boxes.shape))\n",
    "print(\"classes.shape = \" + str(classes.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Non-max Suppression\n",
    "\n",
    "Incluso después de filtrar por **umbral** sobre las class scores, aún termina con muchas casillas superpuestas. Un segundo filtro para seleccionar las casillas correctas se denomina supresión no máxima (NMS).\n",
    "\n",
    "<img src=\"image/nb_images/non-max-suppression.png\" style=\"width:500px;height:400;\">\n",
    "<caption><center> <u> <b>Figure 7</b> </u>: En este ejemplo, el modelo predijo 3 autos, pero en realidad son 3 predicciones del mismo auto. Ejecutar la supresión no máxima (NMS) seleccionará solo la más precisa (probabilidad más alta) de las 3 casillas. <br> </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La supresión no máxima utiliza la función muy importante llamada **\"Intersection over Union\"**, o IoU.\n",
    "\n",
    "<img src=\"image/nb_images/iou.png\" style=\"width:500px;height:400;\">\n",
    "\n",
    "<caption><center> <u> Figure 8 </u>: Definición de \"Intersection over Union\". <br> </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Implementando iou():***\n",
    "- En este código, usamos la convención de que (0,0) es la esquina superior izquierda de una imagen, (1,0) es la esquina superior derecha y (1,1) es la esquina inferior derecha. En otras palabras, el origen (0,0) comienza en la esquina superior izquierda de la imagen. A medida que x aumenta, nos movemos hacia la derecha. A medida que y aumenta, nos movemos hacia abajo.\n",
    "- Para este ejercicio, definimos un cuadro usando sus dos esquinas: superior izquierda $(x_1, y_1)$ e inferior derecha $(x_2,y_2)$, en lugar de usar el punto medio, alto y ancho. (Esto hace que sea un poco más fácil calcular la intersección).\n",
    "- Para calcular el área de un rectángulo, multiplica su altura $(y_2 - y_1)$ por su ancho $(x_2 - x_1)$. (Dado que $(x_1,y_1)$ es la parte superior izquierda y $x_2,y_2$ son la parte inferior derecha, estas diferencias no deberían ser negativas.\n",
    "- Para encontrar la **intersección** de las dos cajas $(xi_{1}, yi_{1}, xi_{2}, yi_{2})$:\n",
    "    - Siéntase libre de dibujar algunos ejemplos en papel para aclarar esto conceptualmente.\n",
    "    - La esquina superior izquierda de la intersección $(xi_{1}, yi_{1})$ se encuentra comparando las esquinas superiores izquierdas $(x_1, y_1)$ de los dos cuadros y encontrando un vértice que tenga una coordenada x que está más cerca de la derecha, y la coordenada y que está más cerca de la parte inferior.\n",
    "    - La esquina inferior derecha de la intersección $(xi_{2}, yi_{2})$ se encuentra comparando las esquinas inferiores derechas $(x_2,y_2)$ de los dos cuadros y encontrando un vértice cuya coordenada x esté más cerca de la izquierda y la coordenada y que está más cerca de la parte superior.\n",
    "    - Los dos boxes **pueden no tener intersección**. Puede detectar esto si las coordenadas de intersección que calcula terminan siendo las esquinas superior derecha y/o inferior izquierda de un cuadro de intersección. Otra forma de pensar en esto es si calcula la altura $(y_2 - y_1)$ o el ancho $(x_2 - x_1)$ y encuentra que al menos una de estas longitudes es negativa, entonces no hay intersección (el área de intersección es cero ). \n",
    "    - Los dos cuadros pueden intersecarse en los **bordes o vértices**, en cuyo caso el área de intersección sigue siendo cero. Esto sucede cuando la altura o el ancho (o ambos) de la intersección calculada es cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(box1, box2):\n",
    "    \"\"\"Implement the intersection over union (IoU) between box1 and box2\n",
    "    Arguments:\n",
    "    box1 -- first box, list object with coordinates (box1_x1, box1_y1, box1_x2, box1_y2)\n",
    "    box2 -- second box, list object with coordinates (box2_x1, box2_y1, box2_x2, box2_y2)\n",
    "    \"\"\"\n",
    "    (box1_x1, box1_y1, box1_x2, box1_y2) = box1\n",
    "    (box2_x1, box2_y1, box2_x2, box2_y2) = box2\n",
    "\n",
    "    xi1 = max(box1_x1, box2_x1)\n",
    "    yi1 = max(box1_y1, box2_y1)\n",
    "    xi2 = min(box1_x2, box2_x2)\n",
    "    yi2 = min(box1_y2, box2_y2)\n",
    "\n",
    "    inter_width = max(0, yi2 - yi1)\n",
    "    inter_height = max(0, xi2 - xi1)\n",
    "    inter_area = inter_width* inter_height\n",
    "\n",
    "    box1_area = (box1_x2 - box1_x1)*(box1_y2-box1_y1)\n",
    "    box2_area = (box2_x2 - box2_x1)*(box2_y2-box2_y1)\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "\n",
    "    # Calculo de IoU\n",
    "    iou = inter_area/union_area\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iou por cajas que se cruzan = 0.14285714285714285\n",
      "iou para cajas que no se cruzan = 0.0\n",
      "iou para cajas que solo se tocan en los vértices = 0.0\n",
      "iou para cajas que solo se tocan en los bordes = 0.0\n"
     ]
    }
   ],
   "source": [
    "## Caso 1: Interseccion de caajas\n",
    "box1 = (2, 1, 4, 3)\n",
    "box2 = (1, 2, 3, 4)\n",
    "\n",
    "print(\"iou por cajas que se cruzan = \" + str(iou(box1, box2)))\n",
    "assert iou(box1, box2) < 1, \"El área de intersección debe ser siempre menor o igual que el área de unión.\"\n",
    "assert np.isclose(iou(box1, box2), 0.14285714), \"Valor incorrecto. Verifique su implementación. Problema con las cajas que se cruzan\"\n",
    "\n",
    "## Caso 2: Las cajas no se cruzan\n",
    "box1 = (1,2,3,4)\n",
    "box2 = (5,6,7,8)\n",
    "print(\"iou para cajas que no se cruzan = \" + str(iou(box1,box2)))\n",
    "assert iou(box1, box2) == 0, \"La intersección debe ser 0\"\n",
    "\n",
    "## Caso 3: Las cajas se cruzan solo en los vértices\n",
    "box1 = (1,1,2,2)\n",
    "box2 = (2,2,3,3)\n",
    "print(\"iou para cajas que solo se tocan en los vértices = \" + str(iou(box1,box2)))\n",
    "assert iou(box1, box2) == 0, \"La intersección en los vértices debe ser 0\"\n",
    "\n",
    "## Caso 4: Las cajas se cruzan solo en el borde\n",
    "box1 = (1,1,3,3)\n",
    "box2 = (2,3,3,4)\n",
    "print(\"iou para cajas que solo se tocan en los bordes = \" + str(iou(box1,box2)))\n",
    "assert iou(box1, box2) == 0, \"La intersección en los bordes debe ser 0\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 - YOLO Non-max Suppression\n",
    "\n",
    "Ahora está listo para implementar la non-max suppression. Los pasos clave son:\n",
    "1. Seleccione la casilla que tenga la score más alta.\n",
    "2. Calcule la superposición de este cuadro con todos los demás cuadros y elimine los cuadros que se superponen significativamente (iou >= `iou_threshold`).\n",
    "3. Vuelva al paso 1 e itere hasta que no haya más casillas con una score más baja que la casilla seleccionada actualmente.\n",
    "Esto eliminará todos los cuadros que tengan una gran superposición con los cuadros seleccionados. Solo quedan las *\"mejores\"* cajas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Implemente yolo_non_max_suppression()*** usando TensorFlow. \n",
    "\n",
    "TensorFlow tiene dos funciones integradas que se usan para implementar la supresión no máxima (por lo que en realidad no necesita usar su implementación `iou()`):\n",
    "\n",
    "[tf.image.non_max_suppression()](https://www.tensorflow.org/api_docs/python/tf/image/non_max_suppression) Elimina las cajas que tienen una gran superposición de intersección sobre unión (IOU) con las cajas previamente seleccionadas. Los cuadros delimitadores se proporcionan como [y1, x1, y2, x2], donde (y1, x1) y (y2, x2) son las coordenadas de cualquier par diagonal de esquinas del cuadro y las coordenadas se pueden proporcionar normalizadas (es decir, dentro del intervalo [0, 1]) o absoluta. \n",
    "\n",
    "Devuelve un tensor entero de forma [M] que representa los índices seleccionados del tensor de cajas, donde M <= max_output_size\n",
    "\n",
    "``` python\n",
    "tf.image.non_max_suppression(\n",
    "    boxes,\n",
    "    scores,\n",
    "    max_output_size,\n",
    "    iou_threshold=0.5,\n",
    "    name=None\n",
    ")\n",
    "```\n",
    "\n",
    "[tf.gather()](https://www.tensorflow.org/api_docs/python/tf/gather)\n",
    "Reúne slices de `reference` de acuerdo con los `indices`, indices debe ser un tensor entero de cualquier dimensión (a menudo 1-D).\n",
    "\n",
    "``` python\n",
    "tf.gather(\n",
    "    reference,\n",
    "    indices\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_non_max_suppression(scores, boxes, classes, max_boxes = 10, iou_threshold = 0.5):\n",
    "    \"\"\"\n",
    "    Applies Non-max suppression (NMS) to set of boxes\n",
    "    \n",
    "    Arguments:\n",
    "    scores -- tensor of shape (None,), output of yolo_filter_boxes()\n",
    "    boxes -- tensor of shape (None, 4), output of yolo_filter_boxes() that have been scaled to the image size (see later)\n",
    "    classes -- tensor of shape (None,), output of yolo_filter_boxes()\n",
    "    max_boxes -- integer, maximum number of predicted boxes you'd like\n",
    "    iou_threshold -- real value, \"intersection over union\" threshold used for NMS filtering\n",
    "    \"\"\"\n",
    "\n",
    "    max_boxes_tensor = tf.cast(max_boxes, dtype = 'int32')\n",
    "\n",
    "    # Para obtener la lista de índices correspondientes a las mejores cajas que guardaremos\n",
    "    nms_indices = tf.image.non_max_suppression(boxes, scores,\n",
    "                    max_output_size = max_boxes_tensor, iou_threshold = iou_threshold)\n",
    "\n",
    "    # Use tf.gather() para seleccionar los scores, boxes y classes de los nms_indices\n",
    "    scores = tf.gather(scores, nms_indices)\n",
    "    boxes = tf.gather(boxes, nms_indices)\n",
    "    classes = tf.gather(classes, nms_indices)\n",
    "\n",
    "    return scores, boxes, classes\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(10)\n",
    "scores = tf.random.normal([54,], mean=1, stddev=4, seed = 1)\n",
    "boxes = tf.random.normal([54, 4], mean=1, stddev=4, seed = 1)\n",
    "classes = tf.random.normal([54,], mean=1, stddev=4, seed = 1)\n",
    "scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxes = 10\n",
      "scores[2] = 8.147684\n",
      "boxes[2] = [ 6.0797963   3.743308    1.3914018  -0.34089637]\n",
      "classes[2] = 1.7079165\n",
      "scores.shape = (10,)\n",
      "boxes.shape = (10, 4)\n",
      "classes.shape = (10,)\n"
     ]
    }
   ],
   "source": [
    "print(\"boxes = \" + str(len(boxes)))\n",
    "print(\"scores[2] = \" + str(scores[2].numpy()))\n",
    "print(\"boxes[2] = \" + str(boxes[2].numpy()))\n",
    "print(\"classes[2] = \" + str(classes[2].numpy()))\n",
    "print(\"scores.shape = \" + str(scores.numpy().shape))\n",
    "print(\"boxes.shape = \" + str(boxes.numpy().shape))\n",
    "print(\"classes.shape = \" + str(classes.numpy().shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 - Terminando el filtrado\n",
    "\n",
    "Es hora de implementar una **función que tome la salida de la CNN profunda** (la codificación dimensional 19x19x5x85) y **filtre todas las casillas** usando las funciones que acaba de implementar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Implemente `yolo_eval()`*** que toma la salida de la codificación de YOLO y filtra las boxes usando el umbral de score y NMS. Solo hay un último detalle de implementación que debe conocer. Hay algunas formas de representar cajas, como a través de sus esquinas o a través de su punto medio y alto/ancho. YOLO convierte entre algunos de estos formatos en diferentes momentos, utilizando las siguientes funciones (que hemos proporcionado):\n",
    "\n",
    "```python\n",
    "boxes = yolo_boxes_to_corners(box_xy, box_wh) \n",
    "```\n",
    "convierte las coordenadas de la caja de yolo (x,y,w,h) en las coordenadas de las esquinas de la caja (y1, x1, y2, x2) para ajustarse a la entrada de `yolo_filter_boxes`\n",
    "\n",
    "```python\n",
    "boxes = scale_boxes(boxes, image_shape)\n",
    "```\n",
    "La red de YOLO fue entrenada para funcionar con imágenes de 608x608. Si está probando estos datos en una imagen de diferente tamaño, por ejemplo, el conjunto de datos de detección de automóviles tenía imágenes de 720x1280, `este paso vuelve a escalar los cuadros para que se puedan trazar sobre la imagen original de 720x1280.`\n",
    "\n",
    "No te preocupes por estas dos funciones; le mostraremos dónde deben ser llamados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_boxes_to_corners(box_xy, box_wh):\n",
    "    \"\"\"Convertir predicciones de caja de YOLO en esquinas de cuadro delimitador.\"\"\"    \n",
    "    # box_xy (19x19x5x2)\n",
    "    # box_wh (19x19x5x2)\n",
    "\n",
    "    box_mins = box_xy - (box_wh / 2.)\n",
    "    box_maxes = box_xy + (box_wh / 2.)\n",
    "\n",
    "    return tf.concat([box_mins[...,1:2],\n",
    "                      box_mins[...,0:1],\n",
    "                      box_maxes[..., 1:2],\n",
    "                      box_maxes[..., 0:1]], axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_boxes(boxes, image_shape):\n",
    "    \"\"\" Escala los boxes predichos para poder dibujarlos en la imagen\"\"\"\n",
    "    height = image_shape[0]\n",
    "    width = image_shape[1]\n",
    "    image_dims = tf.cast([height, width]*2, dtype = 'float32')\n",
    "    image_dims = tf.reshape(image_dims, [1,4])\n",
    "    boxes = boxes * image_dims # Forma de boxes (19x19x5x4)\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_eval(yolo_outputs, image_shape = (720, 1280), max_boxes=10, score_threshold=.6, iou_threshold=.5):\n",
    "    \"\"\"Convierte el output de codificacion de YOLO (muchos cuadros) en sus boxes predichos junto con sus scores, coordenadas de caja y clases.\n",
    "    Arguments:\n",
    "    Para una imagen\n",
    "    yolo_outputs -- output of the encoding model (for image_shape of (608, 608, 3)), contains 4 tensors:\n",
    "                    box_xy: tensor of shape (None, 19, 19, 5, 2)\n",
    "                    box_wh: tensor of shape (None, 19, 19, 5, 2)\n",
    "                    box_confidence: tensor of shape (None, 19, 19, 5, 1)\n",
    "                    box_class_probs: tensor of shape (None, 19, 19, 5, 80)\n",
    "    image_shape -- tensor de forma (2,) que contiene la forma del input, en este notebook usamos (608., 608.) (tiene que ser dtype float32)\n",
    "    max_boxes -- integer, maximum number of predicted boxes you'd like\n",
    "    score_threshold -- real value, if [ highest class probability score < threshold], then get rid of the corresponding box\n",
    "    iou_threshold -- real value, \"intersection over union\" threshold used for NMS filtering\n",
    "    \n",
    "    Returns:\n",
    "    scores -- tensor of shape (None, ), predicted score for each box\n",
    "    boxes -- tensor of shape (None, 4), predicted box coordinates\n",
    "    classes -- tensor of shape (None,), predicted class for each box\n",
    "    \"\"\"\n",
    "\n",
    "    #Recuperar salidas del modelo YOLO\n",
    "    box_xy, box_wh, box_confidence, box_class_probs = yolo_outputs\n",
    "\n",
    "    # Convierta los boxes para que estén listos para las funciones de filtrado (convierta los cuadros box_xy y box_wh en coordenadas de esquina)\n",
    "    boxes = yolo_boxes_to_corners(box_xy, box_wh)\n",
    "\n",
    "    # Use una de las funciones que ha implementado para realizar el filtrado de score con un umbral de score_threshold\n",
    "    scores, boxes, classes = yolo_filter_boxes(boxes, box_confidence, box_class_probs, score_threshold)\n",
    "\n",
    "    # Escale los boxes a la forma original de la imagen (720x1280 o lo que sea)\n",
    "    # La red fue entrenada para ejecutarse en imágenes de 608x608 \n",
    "    boxes = scale_boxes(boxes, image_shape)\n",
    "\n",
    "    # Use una de las funciones que ha implementado para realizar la supresión no máxima con\n",
    "    # número máximo de boxes establecido en max_boxes y un umbral de iou_threshold\n",
    "    scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes, max_boxes, iou_threshold)\n",
    "\n",
    "    return scores, boxes, classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(10)\n",
    "yolo_outputs = (tf.random.normal([19, 19, 5, 2], mean=1, stddev=4, seed = 1),\n",
    "                tf.random.normal([19, 19, 5, 2], mean=1, stddev=4, seed = 1),\n",
    "                tf.random.normal([19, 19, 5, 1], mean=1, stddev=4, seed = 1),\n",
    "                tf.random.normal([19, 19, 5, 80], mean=1, stddev=4, seed = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores[2] = 171.60194\n",
      "boxes[2] = [-1240.3483 -3212.5881  -645.78    2024.3052]\n",
      "classes[2] = 16\n",
      "scores.shape = (10,)\n",
      "boxes.shape = (10, 4)\n",
      "classes.shape = (10,)\n"
     ]
    }
   ],
   "source": [
    "scores, boxes, classes = yolo_eval(yolo_outputs)\n",
    "print(\"scores[2] = \" + str(scores[2].numpy()))\n",
    "print(\"boxes[2] = \" + str(boxes[2].numpy()))\n",
    "print(\"classes[2] = \" + str(classes[2].numpy()))\n",
    "print(\"scores.shape = \" + str(scores.numpy().shape))\n",
    "print(\"boxes.shape = \" + str(boxes.numpy().shape))\n",
    "print(\"classes.shape = \" + str(classes.numpy().shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Pruebe el modelo preentrenado de YOLO en imágenes\n",
    "\n",
    "En esta parte, utilizará un modelo previamente entrenado y lo probará en el conjunto de datos de detección de automóviles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Definición de clases, anchors y forma de imagen\n",
    "\n",
    "Está tratando de detectar 80 clases y está utilizando 5 cuadros de anclaje(anchor boxes). La información de las 80 clases y 5 cajas está reunida en dos archivos: \"coco_classes.txt\" y \"yolo_anchors.txt\". Leerá los nombres de las clases y los anchors de los archivos de texto. `El conjunto de datos de detección de automóviles tiene imágenes de 720x1280`, que **se procesan previamente en imágenes de 608x608**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = read_classes(\"model_data/coco_classes.txt\")\n",
    "anchors = read_anchors(\"model_data/yolo_anchors.txt\")\n",
    "model_image_size = (608, 608) # Igual que el tamaño de capa de entrada de yolo_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.57273 , 0.677385],\n",
       "       [1.87446 , 2.06253 ],\n",
       "       [3.33843 , 5.47434 ],\n",
       "       [7.88282 , 3.52778 ],\n",
       "       [9.77052 , 9.16828 ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Cargando un modelo preentrenado\n",
    "\n",
    "* Entrenar un modelo YOLO lleva mucho tiempo y requiere un conjunto de datos bastante grande de cuadros delimitadores etiquetados para una amplia gama de clases objetivo.\n",
    "* Va a cargar un modelo Keras YOLO preentrenado existente almacenado en \"yolo.h5\".\n",
    "* Estos pesos provienen del sitio web oficial de YOLO y se convirtieron mediante una función escrita por Allan Zelener. Las referencias se encuentran al final de este cuaderno. Técnicamente, estos son los parámetros del modelo \"YOLOv2\", pero simplemente nos referiremos a él como \"YOLO\" en este cuaderno.\n",
    "\n",
    "Ejecute la celda a continuación para cargar el modelo desde este archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model = load_model('model_data/yolo.h5', compile = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto carga los pesos de un modelo YOLO entrenado. Aquí hay un resumen de las capas que contiene su modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recordar:** este modelo convierte un lote preprocesado de imágenes de entrada (forma: (m, 608, 608, 3)) en un tensor de forma (m, 19, 19, 5, 85) como se explica en la Figura (2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Convierta la salida del modelo en tensores de cuadro delimitador utilizables\n",
    "\n",
    "La salida de `yolo_model` es un tensor (m, 19, 19, 5, 85) que necesita pasar por un procesamiento y una conversión. La siguiente celda hace eso por ti.\n",
    "Si tiene curiosidad acerca de cómo se implementa `yolo_head`, puede encontrar la definición de la función en el archivo ['keras_yolo.py'](https://github.com/allanzelener/YAD2K/blob/master/yad2k/models/keras_yolo.py).  El archivo se encuentra en su espacio de trabajo en esta ruta 'yad2k/models/keras_yolo.py'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, image_data = preprocess_image('./images/test.jpg', model_image_size = (608, 608))\n",
    "yolo_model_outputs = yolo_model(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_outputs = yolo_head(yolo_model_outputs, anchors, len(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable `yolo_outputs` se definirá como un conjunto de 4 tensores que luego puede usar como entrada para su función `yolo_eval`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 - Filtrando cajas\n",
    "\n",
    "`yolo_outputs` te dio todos los cuadros predichos de `yolo_model` en el formato correcto. Ahora está listo para realizar el filtrado y seleccionar solo las mejores casillas. Llamemos ahora a `yolo_eval`, que habías implementado previamente, para hacer esto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, boxes, classes = yolo_eval(yolo_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 - Ejecutar el gráfico en una imagen\n",
    "\n",
    "Ha creado un gráfico que se puede resumir de la siguiente manera:\n",
    "\n",
    "1. <font color='purple'> yolo_model.input </font> se le da a `yolo_model`. El modelo se utiliza para calcular la salida. <font color='purple'> yolo_model.output </font>\n",
    "2. <font color='purple'> yolo_model.output </font> es procesado por `yolo_head`. Te dá <font color='purple'> yolo_outputs </font>\n",
    "3. <font color='purple'> yolo_outputs </font> pasa por una función de filtrado, `yolo_eval`. Muestra sus predicciones: <font color='purple'> scores, boxes, classes </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, hemos implementado para usted la función `predict(image_file)`, que ejecuta el gráfico para probar YOLO en una imagen para calcular `out_scores`, `out_boxes`, `out_classes`.\n",
    "El siguiente código también usa la siguiente función:\n",
    "```python\n",
    "image, image_data = preprocess_image(\"images/\" + image_file, model_image_size = (608, 608))\n",
    "```\n",
    "que abre el archivo de imagen y escala, remodela y normaliza la imagen. Devuelve las salidas:\n",
    "\n",
    "- image: una representación de python (PIL) de su imagen utilizada para dibujar cuadros. No necesitarás usarlo (imagen previa)\n",
    "- image_data: Un numpy-array representando la imagen. Esta será la entrada a la CNN. (array, de la imagen reformada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_file):\n",
    "    \"\"\"\n",
    "     Ejecuta el gráfico para predecir cuadros para \"image_file\". Imprime y grafica las predicciones.\n",
    "    \n",
    "     Argumentos:\n",
    "     image_file: nombre de una imagen almacenada en la carpeta \"image/images\".\n",
    "    \n",
    "     Devoluciones:\n",
    "     out_scores -- tensor de forma (None, ), puntajes de los cuadros predichos\n",
    "     out_boxes -- tensor de forma (None, 4), coordenadas de los cuadros predichos\n",
    "     out_classes -- tensor de forma (None, ), índice de clase de los cuadros predichos\n",
    "    \n",
    "     Nota: \"None\" en realidad representa el número de cajas pronosticadas, varía entre 0 y max_boxes.\n",
    "     \"\"\"\n",
    "\n",
    "    # Preprocesando la imagen\n",
    "    image, image_data = preprocess_image(\"image/images/\" + image_file, model_image_size = (608,608))\n",
    "\n",
    "    # Su salida es de forma (1, 19, 19, 5, 85)\n",
    "    yolo_model_outputs = yolo_model(image_data)\n",
    "\n",
    "    # Pero yolo_eval toma como entrada un tensor que contiene 4 tensores: box_xy, box_wh, box_confidence & box_class_probs\n",
    "    yolo_outputs = yolo_head(yolo_model_outputs, anchors, len(class_names))\n",
    "\n",
    "    out_scores, out_boxes, out_classes = yolo_eval(yolo_outputs, [image.size[1],  image.size[0]], 10, 0.3, 0.5)\n",
    "\n",
    "    print('Se encontró {} cajas para {}'.format(len(out_boxes), \"image/images/\" + image_file))\n",
    "    # Genere colores para dibujar cuadros delimitadores.\n",
    "    colors = get_colors_for_classes(len(class_names))\n",
    "    \n",
    "    # Dibujar cuadros delimitadores en el archivo de imagen\n",
    "    # draw_boxes(image, out_scores, out_boxes, out_classes, class_names, colors, image_shape)\n",
    "    draw_boxes(image, out_scores, out_boxes, out_classes ,class_names, colors)\n",
    "\n",
    "    # Guardar el cuadro delimitador predicho en la imagen\n",
    "    image.save(os.path.join(\"out\", str(image_file).split('.')[0] + \"_annotated.\" + str(image_file).split('.')[1]), quality = 100)\n",
    "\n",
    "    # Mostrar los resultados en el notebook\n",
    "    output_image = Image.open(os.path.join(\"out\", str(image_file).split('.')[0] + \"_annotated.\" + str(image_file).split('.')[1]))\n",
    "    plt.imshow(output_image)\n",
    "\n",
    "    return out_scores, out_boxes, out_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute la siguiente celda en la imagen \"test.jpg\" para verificar que su función sea correcta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_scores, out_boxes, out_classes = predict(\"0001.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tuviera que ejecutarlo en un bucle for sobre todas sus imágenes. Esto es lo que obtendrías:\n",
    "\n",
    "<center>\n",
    "<video width=\"400\" height=\"200\" src=\"image/nb_images/pred_video_compressed2.mp4\" type=\"video/mp4\" controls>\n",
    "</video>\n",
    "</center>\n",
    "\n",
    "<caption><center> Predicciones del modelo YOLO en imágenes tomadas con una cámara mientras conduce por Silicon Valley <br> [drive.ai](https://www.drive.ai/) </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <font color='green'>Lo que debes recordar:\n",
    "    \n",
    "- YOLO es un modelo de detección de objetos de última generación que es rápido y preciso\n",
    "- Ejecuta una imagen de entrada a través de una CNN que genera un volumen dimensional de 19x19x5x85.\n",
    "- La codificación(encoding) se puede ver como una cuadrícula donde cada una de las celdas de 19x19 contiene información sobre 5 casillas.\n",
    "- Filtra a través de todas las casillas utilizando supresión no máxima. Específicamente: \n",
    "    - Score thresholding en la probabilidad de detectar una clase para mantener solo casillas precisas (alta probabilidad)\n",
    "    - Umbral de intersección sobre unión (IoU) para eliminar cajas superpuestas\n",
    "- Debido a que entrenar un modelo YOLO a partir de pesos inicializados aleatoriamente no es trivial y requiere un gran conjunto de datos, así como muchos cálculos, en este ejercicio usamos parámetros de modelo previamente entrenados. Si lo desea, también puede intentar ajustar el modelo YOLO con su propio conjunto de datos, aunque este no sería un ejercicio trivial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Referencias**: Las ideas presentadas en este cuaderno provienen principalmente de los dos artículos de YOLO. La implementación aquí también tomó una inspiración significativa y usó muchos componentes del repositorio GitHub de Allan Zelener. Los pesos previamente entrenados utilizados en este ejercicio provienen del sitio web oficial de YOLO.\n",
    "- Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi - [You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/abs/1506.02640) (2015)\n",
    "- Joseph Redmon, Ali Farhadi - [YOLO9000: Better, Faster, Stronger](https://arxiv.org/abs/1612.08242) (2016)\n",
    "- Allan Zelener - [YAD2K: Yet Another Darknet 2 Keras](https://github.com/allanzelener/YAD2K)\n",
    "- The official YOLO website (https://pjreddie.com/darknet/yolo/) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4edecc0c6a4f0e1e3de79ca77741107a175241f6f71b1c161b36dd6ac31a9479"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
